# This yaml file specifies how to subset a df of the zillow training data
# Each main name will the the file (pkl) under which the subsetted df
# will be stored
#

# The name at the top of this will be the name of the output pickle file with the subsetted features (eg: features_1st.pkl in the first example below)
#     features: This specifies the list of features to subset the main df
#         transform:
#              <name-of-feature>:
#                   <transformation-type>:
#                       onehot | normalize:
#                            onehot options:
#                            normalize options: std-scaler | min-max
#

features_1st:
    features: land_use_type, census_tract_block_raw, county_id, num_rooms, fips, num_bathrooms, logerror, num_bedrooms, tax_total, tax_land, county_land_use_code, tax_total_year, tax_built, area_living_calc, year_built, num_bathrooms_calc, city_id, area_living, area_lot
    train_test_split:
        split_ratio: 0.3
        random_state: 42
    transform:
        land_use_type:
            onehot: some-junk-for-now
        census_tract_block_raw:
            normalize: standard
        county_id:
            normalize: standard
        num_rooms:
            normalize: standard
        fips:
            normalize: standard
        num_bathrooms:
            normalize: standard
        num_bedrooms:
            normalize: standard
        tax_total:
            normalize: standard
        tax_land:
            normalize: standard
        county_land_use_code:
            normalize: standard
        tax_total_year:
            normalize: standard
        tax_built:
            normalize: standard
        area_living_calc:
            normalize: standard
        year_built:
            normalize: standard
        num_bathrooms_calc:
            normalize: standard
        city_id:
            normalize: standard
        area_living:
            normalize: standard
        area_lot:
            normalize: standard


