{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from fastText import train_supervised\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "training_data = Path('/home/ggopalan/Learning/NLP/quora_insincere/qiqc_train_set.txt')\n",
    "test_data = Path('/home/ggopalan/Learning/NLP/quora_insincere/qiqc_test_set.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print results of the test\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext_default(train_data, epochs=25, learning_rate=1.0, wordNgrams=2):\n",
    "    # train_supervised uses the same arguments and defaults as the fastText cli\n",
    "    model = train_supervised(\n",
    "        input=train_data, epoch=epochs, lr=learning_rate, wordNgrams=wordNgrams, verbose=2, minCount=1\n",
    "    )\n",
    "    # print_results(*model.test(valid_data))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext_losshs(train_data, epochs=25, learning_rate=1.0, wordNgrams=2):\n",
    "    model = train_supervised(\n",
    "        input=train_data, epoch=epochs, lr=learning_rate, wordNgrams=wordNgrams, verbose=2, minCount=1,\n",
    "        loss=\"hs\"\n",
    "    )\n",
    "    # print_results(*model.test(valid_data))\n",
    "    # model.save_model(\"cooking.bin\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_quantize(train_data, retrain=True, cutoff=100000):\n",
    "    model.quantize(input=train_data, qnorm=True, retrain=retrain, cutoff=cutoff)\n",
    "    # print_results(*model.test(valid_data))\n",
    "    # model.save_model(\"cooking.ftz\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run default train\n",
    "model_default = train_fasttext_default(str(training_data.absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default.save_model('/home/ggopalan/Learning/NLP/quora_insincere/default_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test the model with test data\n",
    "test_output = model_default.test(str(test_data.absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t130646\n",
      "P@1\t0.950\n",
      "R@1\t0.950\n"
     ]
    }
   ],
   "source": [
    "print_results(*test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(600659, 0.6939211765743958, 0.6939211765743958)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
