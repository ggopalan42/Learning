{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tables        | Are           | Cool  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| col 3 is      | right-aligned | $1600 |\n",
    "| col 2 is      | centered      |   $12 |\n",
    "| zebra stripes | are neat      |    $1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Expt Num | Model         | F1 Score            |  epochs  |  lr   |   wordNgrams  |\n",
    "| ---------|---------------|---------------------|----------|-------|---------------|\n",
    "|    1     |  default      | 0.5525770000000000  |    25    |  1.0  |       2       |\n",
    "|    2     |  default      | 0.5460660000000000  |   100    |  1.0  |       2       |\n",
    "|    3     |  default      | 0.5498856582816073  |   100    |  0.1  |       2       |\n",
    "|    4     |  default      | 0.5695227616558932  |    25    |  1.0  |       3       |\n",
    "|    5     |  default      | 0.5772041248378066  |    25    |  1.0  |       4       |\n",
    "|    6     |  default      | 0.5683045171871797  |    25    |  1.0  |       5       |\n",
    "|    7     |  default      | 0.5483274021352313  |    25    |  1.0  |       6       |\n",
    "|    8     |  default      | 0.5745956497490240  |    25    |  0.1  |       4       |\n",
    "|    9     |  default      | 0.5726129216695254  |    25    |  0.01 |       4       |\n",
    "|   10     |  default      | 0.5740194010965838  |   100    |  0.01 |       4       |\n",
    "|   11     |  default      | 0.5741746761387380  |  1000    |  0.01 |       4       |\n",
    "|   12     |  default      | 0.5744753571672705  |  1000    |  0.1  |       4       |\n",
    "|   13     |  default      | 0.5692476963278779  |   100    |  1.0  |       4       |\n",
    "|   14     |  default      | 0.5711939787889154  |  1000    |  1.0  |       4       |\n",
    "|----------|---------------|---------------------|----------|-------|---------------|\n",
    "|   15     |  losshs       | 0.5727887401683456  |   100    |  1.0  |       4       |\n",
    "|   16     |  losshs       | 0.5655720560552185  |    25    |  1.0  |       4       |\n",
    "|    x     |  losshs       | 0.5726968517380318  |  1000    |  1.0  |       4       |\n",
    "|    x     |  losshs       |                     |    25    |  1.0  |               |\n",
    "|    x     |  losshs       |                     |    25    |  1.0  |               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.metrics import f1_score\n",
    "from fastText import train_supervised\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "qiqc_expt_train_data = Path('//data/data1/datasets/kaggle/quora_insincere/output/qiqc_expt_train_set.txt')\n",
    "qiqc_expt_test_data = Path('//data/data1/datasets/kaggle/quora_insincere/output/qiqc_expt_test_set.txt')\n",
    "qiqc_expt_model_path = Path('/data/data1/datasets/kaggle/quora_insincere/models/qiqc_expt_fasttext_def.bin')\n",
    "qiqc_expt_losshs_model_path = Path('/data/data1/datasets/kaggle/quora_insincere/models/qiqc_expt_fasttext_losshs.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print results of the test\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext_default(train_data, epochs=25, learning_rate=1.0, wordNgrams=2):\n",
    "    # train_supervised uses the same arguments and defaults as the fastText cli\n",
    "    model = train_supervised(\n",
    "        input=train_data, epoch=epochs, lr=learning_rate, wordNgrams=wordNgrams, verbose=2, minCount=1\n",
    "    )\n",
    "    # print_results(*model.test(valid_data))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext_losshs(train_data, epochs=25, learning_rate=1.0, wordNgrams=2):\n",
    "    model = train_supervised(\n",
    "        input=train_data, epoch=epochs, lr=learning_rate, wordNgrams=wordNgrams, verbose=2, minCount=1,\n",
    "        loss=\"hs\"\n",
    "    )\n",
    "    # print_results(*model.test(valid_data))\n",
    "    # model.save_model(\"cooking.bin\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_quantize(train_data, retrain=True, cutoff=100000):\n",
    "    model.quantize(input=train_data, qnorm=True, retrain=retrain, cutoff=cutoff)\n",
    "    # print_results(*model.test(valid_data))\n",
    "    # model.save_model(\"cooking.ftz\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# model_default = train_fasttext_default(str(qiqc_expt_train_data.absolute()), epochs=1000, learning_rate=1.0, wordNgrams=4)\n",
    "model_losshs = train_fasttext_losshs(str(qiqc_expt_train_data.absolute()), epochs=1000, learning_rate=1.0, wordNgrams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_default.save_model(str(qiqc_expt_model_path))\n",
    "model_losshs.save_model(str(qiqc_expt_losshs_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__0',), array([1.00001001]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_losshs.predict('my voice range is a2-c5 .  my chest voice goes up to f4 .  included sample in my higher chest range .  what is my voice typ')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_questions(model, expt_test_data):\n",
    "    ''' From the test data, extract the question and predict using the trained model '''\n",
    "    y_pred = []\n",
    "    y_actual = []\n",
    "    with qiqc_expt_test_data.open() as test_fh:\n",
    "        for line in test_fh:\n",
    "            if line.strip().startswith('qid'):\n",
    "                continue\n",
    "            # the label below is the actual label from the test split\n",
    "            # The label format is: __label__0 or __label__1\n",
    "            label = line.strip()[0:10]\n",
    "            # Add the actual label 0 or 1 to y_actual\n",
    "            y_actual.append(label[-1])\n",
    "            \n",
    "            question = line.strip()[11:]\n",
    "            pred = model.predict(question)\n",
    "            # The pred from abobe is of the format: (('__label__0',), array([1.00001001]))\n",
    "            # So below shenanigans needs to be done to get to the actual 0 or 1 label\n",
    "            y_pred.append(pred[0][0][-1])\n",
    "    return y_actual, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual, y_pred = predict_questions(model_losshs, qiqc_expt_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5726968517380318"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_actual, y_pred, pos_label='1', average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
